---
title: "ADHDCYCLE Daily Analysis Pipeline (Restored & Commented)"
output:
  html_document:
    toc: true
    fig_caption: true
    number_sections: true
    df_print: default
date: "Last compiled on `r format(Sys.time(), '%B %d, %Y')`"
---

```{r setup, include=FALSE}
# This chunk sets the global options for the entire R Markdown document.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(scipen = 999, digits = 3)
```

# 1\. Load Required Libraries

```{r load-libraries}
# This chunk loads all the packages needed for the analysis.
library(tidyverse)       # A collection of essential packages for data manipulation and visualization (includes dplyr, ggplot2, etc.)
library(janitor)         # Provides functions for cleaning data and table creation.
library(haven)           # For reading data from other statistical software like SPSS (.sav).
library(readxl)          # For reading data from Excel files (.xls, .xlsx).
library(zoo)             # For calculating rolling averages.
library(lubridate)       # For making it easier to work with dates and times.
library(conflicted)      # Helps manage function name conflicts between packages.
library(menstrualcycleR) # For cycle-specific analyses like PACTS scaling.
library(gridExtra)       # For arranging multiple plots on one page.
library(ggvenn)          # For creating Venn diagrams.
library(readr)
library(haven)
library(dplyr)
library(lubridate)
library(tidyr)
library(rlang)
library(visdat)
library(readr)       # For reading CSV files
library(readxl)      # For reading Excel files
library(haven)       # For reading SPSS (SAV) files
library(dplyr)       # For data wrangling
library(lubridate)   # For date parsing/manipulation
library(tidyr)       # For tidying data
library(rlang)       # For tidy evaluation
library(ggvenn)      # For Venn diagrams
library(visdat)      # For missing data visualization

# Explicitly state our function preferences to avoid ambiguity when multiple
# packages have a function with the same name.
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
```

# 2\. Custom Function

```{r define-functions}
# This function is used during the data loading step to ensure key columns
# (like ID, date, and hormone names) have consistent names across all raw files,
# even if the original files used different spellings or capitalization.
standardize_index_names <- function(df) {
  df %>%
    rename_with(~ case_when(
      grepl("\\b([Dd]ate.?rated)\\b", .x) ~ "daterated",
      grepl("^ID$", .x, ignore.case = TRUE) ~ "id",
      grepl("\\b([Ee]strogen|[Ee]stradiol|[Ee]2)\\b", .x) ~ "E2",
      grepl("\\b([Pp]rogesterone|[Pp]4)\\b", .x) ~ "P4",
      TRUE ~ .x # If no match, keep the original name
    ))
}
```

# 3\. CONFIGURATION

```{r config}
# This is the single control panel for the pipeline. To adapt this script for a
# new project, a user should only need to edit the settings in this chunk.

# --- Input File Paths (Using Your Direct, Hardcoded Paths) ---
# Define the full path to each raw data file needed for the analysis.

path_raw_daily <- "~/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/CYCLEADHD/02_datasets/CYCADHD_DAILY/02_data_prep_workspace/2025-08-20/2025.06.02 Daily Master.sav"

path_raw_daily_2 <- "~/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/CYCLEADHD/02_datasets/CYCADHD_DAILY/01_raw_data/2024.04.24.Daily Master.xls"

path_supp_hormones <- "~/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/CYCLEADHD/02_datasets/CYCADHD_DAILY/03_cleaned_data/adhdcyc_daily_2024_07_09_horm.csv"

path_final_hormone_batch <- "~/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/CYCLEADHD/02_datasets/CYCADHD_DAILY/02_data_prep_workspace/2025-08-25/Martel_IRB52576_Results_E2_P4_LH 7-23-2025.csv"

path_final_dates <- "~/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/CYCLEADHD/02_datasets/CYCADHD_DAILY/02_data_prep_workspace/2025-09-26/ADHDCYCLE_menses_ov_dates_FINAL.xls"

path_omit_ids <- "~/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/CYCLEADHD/02_datasets/CYCADHD_DAILY/02_data_prep_workspace/2025-08-26/adhdcyc_omit.xlsx"

# --- Output Folder ---

# Define a base output location and create a unique, timestamped subfolder for this specific run.
output_folder_base <- "~/Library/CloudStorage/Box-Box/00 - CLEAR Lab (Locked Folders)/02 - Data Management, Analysis, and Papers/Studies_Projects/CYCLEADHD/03_analytic_projects/CYCADHD_PRIMARY/03_code_dataedits_output"

output_folder <- file.path(output_folder_base, format(Sys.Date(), "%Y-%m-%d_Run"))
if (!dir.exists(output_folder)) {
  dir.create(output_folder, recursive = TRUE)
}

# --- Variable Lists ---
# Define the final variable names that will be processed and analyzed.

dv_list <- c("CSS_Inatt", "CSS_HypImp", "score_pinball", "score_robot", "BDEFS_Total", "BDEFS_WM_avg", "BDEFS_RI_avg", "UPPS_NU_avg", "UPPS_PU_avg", "UPPS_Premed_avg", "UPPS_Persev_avg", "UPPS_Sens_avg", "DEBQ_Total", "CSS_Inatt_Count", "CSS_Hyp_Count", "CSS_Imp_Count", "CSS_HypImp_Count", paste0("DRSP_", 1:23))
hormlist <- c("E2", "P4", "LH")
alldailyvars <- c(dv_list, hormlist)

# --- Plotting Configuration ---
# This table controls which plots are generated in the final plotting loop.

metrics_to_plot <- tibble::tribble(
  # ~metric_filter: Which calculated metric to plot.
  # ~folder_name: The subfolder where these plots will be saved.
  # ~plot_subtitle: The subtitle that will appear on the plot.
  # ~needs_facet: TRUE if variables have different scales (like raw values) and need separate panels.
  # ~y_axis_label: The label for the y-axis.
  ~metric_filter, ~folder_name, ~plot_subtitle, ~needs_facet, ~y_axis_label,
  "raw", "01_raw_faceted", "Raw Daily Values", TRUE, "Hormone Value",
  "3roll", "02_raw_3roll_faceted", "3-Day Rolling Average", TRUE, "Hormone Value",
  "5roll", "03_raw_5roll_faceted", "5-Day Rolling Average", TRUE, "Hormone Value",
  "zd", "04_person_standardized", "Person-Standardized Daily Values", FALSE, "Standardized Value (Z-Score)",
  "szd", "05_sample_standardized", "Sample-Standardized Daily Values", FALSE, "Standardized Value (Z-Score)"
)
```

```{r}

# --- 1. Load All Data Sources ---
# Read each raw data source from its respective file path
raw_daily <- read_sav(path_raw_daily)
raw_daily_2 <- read_xls(path_raw_daily_2)
supp_hormones_all <- read_csv(path_supp_hormones, show_col_types = FALSE)
final_hormone_batch <- read_csv(path_final_hormone_batch, show_col_types = FALSE)

# --- 2. Standardize id/daterated column names for all sources ---
# Function to rename columns in each data frame to a common set for merging
standardize_index_names <- function(df) {
  df %>%
    rename_with(~ case_when(
      str_detect(.x, regex("^(id|subjectid|ID)$", ignore_case=TRUE)) ~ "id",
      str_detect(.x, regex("^(date.?rated|date_rated|dateRated|rated_date|date)$", ignore_case=TRUE)) ~ "daterated",
      str_detect(.x, regex("^(estradiol|estrogen|e2|E2)$", ignore_case=TRUE)) ~ "E2",
      str_detect(.x, regex("^(progesterone|p4|prog|P4)$", ignore_case=TRUE)) ~ "P4",
      str_detect(.x, regex("^(lh|LH|LH_level)$", ignore_case=TRUE)) ~ "LH",
      str_detect(.x, regex("^(LH_sterr)$", ignore_case=TRUE)) ~ "LH_sterr",
      TRUE ~ .x
    ))
}
# Apply renaming function to all data frames
raw_daily <- standardize_index_names(raw_daily)
raw_daily_2 <- standardize_index_names(raw_daily_2)
supp_hormones_all <- standardize_index_names(supp_hormones_all)
final_hormone_batch <- standardize_index_names(final_hormone_batch)

# --- 3. Create provenance flags for Venn diagram ---
# Add indicator columns to track which source each row came from
raw_daily <- raw_daily %>% mutate(source_raw_daily = TRUE)
raw_daily_2 <- raw_daily_2 %>% mutate(source_raw_daily_2 = TRUE)
supp_hormones_all <- supp_hormones_all %>% mutate(source_supp_hormones = TRUE)
final_hormone_batch <- final_hormone_batch %>% mutate(source_final_batch = TRUE)

# --- 4. Force all daterated columns to "YYYY-MM-DD" string and remove missing keys ---
# Function to parse dates, coercing to "YYYY-MM-DD" format or fallback to "MM/DD/YYYY"
force_ymd <- function(x) {
  x <- as.character(x)
  ymd_x <- suppressWarnings(ymd(x))
  ifelse(!is.na(ymd_x), as.character(ymd_x), suppressWarnings(as.character(mdy(x))))
}
# Apply date coercion to each data frame's 'daterated' column
raw_daily$daterated <- force_ymd(raw_daily$daterated)
raw_daily_2$daterated <- force_ymd(raw_daily_2$daterated)
supp_hormones_all$daterated <- force_ymd(supp_hormones_all$daterated)
final_hormone_batch$daterated <- force_ymd(final_hormone_batch$daterated)

# Remove rows where 'id' or 'daterated' is missing in any data frame
for (df_name in c("raw_daily", "raw_daily_2", "supp_hormones_all", "final_hormone_batch")) {
  df <- get(df_name)
  df <- df %>% filter(!is.na(id) & !is.na(daterated))
  assign(df_name, df)
}

# --- 5. Harmonize column types across all files ---
# Function to make sure columns with the same name have the same type (convert to character if types mismatch)
harmonize_types <- function(dfs) {
  all_names <- unique(unlist(lapply(dfs, names)))
  get_type <- function(x) if (is.null(x)) NA else class(x)[1]
  types <- lapply(dfs, function(df) sapply(all_names, function(nm) get_type(df[[nm]])))
  type_matrix <- do.call(rbind, types)
  mismatches <- sapply(seq_along(all_names), function(j) length(unique(na.omit(type_matrix[,j]))) > 1)
  for (nm in all_names[mismatches]) {
    for (i in seq_along(dfs)) {
      if (!is.null(dfs[[i]][[nm]])) {
        dfs[[i]][[nm]] <- as.character(dfs[[i]][[nm]])
      }
    }
  }
  dfs
}
# Harmonize types across all four sources
data_sources <- harmonize_types(list(raw_daily, raw_daily_2, supp_hormones_all, final_hormone_batch))
raw_daily      <- data_sources[[1]]
raw_daily_2    <- data_sources[[2]]
supp_hormones_all <- data_sources[[3]]
final_hormone_batch <- data_sources[[4]]

# --- 6. Full outer join all data sources by id/daterated ---
# Merge all four data frames fully by 'id' and 'daterated'
all_dfs <- list(raw_daily, raw_daily_2, supp_hormones_all, final_hormone_batch)
merged_df <- Reduce(function(x, y) full_join(x, y, by = c("id", "daterated")), all_dfs)

# --- 7. Maximally fill each key variable from your explicit list ---
# List of all output variables to fill
final_vars <- c(
  "id", "daterated", "TubeNumber", "E2", "P4", "LH", "E2_stderr", "P4_stderr", "LH_sterr",
  "VisitNumbers", "DEBQ_avg", "BDEFS_1", "BDEFS_2", "BDEFS_3", "BDEFS_4", "BDEFS_5", "BDEFS_6",
  "DRSP_1", "DRSP_2", "DRSP_3", "DRSP_4", "DRSP_5", "DRSP_6", "DRSP_7",
  "DRSP_8", "DRSP_9", "DRSP_10", "DRSP_11", "DRSP_12", "DRSP_13", "DRSP_14",
  "DRSP_15", "DRSP_16", "DRSP_17", "DRSP_18", "DRSP_19", "DRSP_20", "DRSP_21",
  "DRSP_22", "DRSP_23", "CSS_B_1", "CSS_B_2", "CSS_B_3", "CSS_B_4",
  "CSS_B_5", "CSS_B_6", "CSS_B_7", "CSS_B_8", "CSS_B_9", "CSS_B_10",
  "CSS_B_11", "CSS_B_12", "CSS_B_13", "CSS_B_14", "CSS_B_15", "CSS_B_16",
  "CSS_B_17", "CSS_B_18", "CSS_Function_1", "CSS_Function_2", "CSS_Function_3",
  "CSS_Function_4", "CSS_Function_5", "CSS_Function_6", "CSS_Function_7",
  "CSS_Function_8", "CSS_Function_9", "CSS_Function_10", "CSS_B2_1",
  "CSS_B2_2", "CSS_B2_3", "CSS_B2_4", "CSS_B2_5", "CSS_B2_6", "CSS_B2_7",
  "CSS_B2_8", "UPPS_1", "UPPS_2", "UPPS_3", "UPPS_4", "UPPS_5", "UPPS_6",
  "UPPS_7", "UPPS_8", "UPPS_9", "UPPS_10", "UPPS_11", "UPPS_12", "UPPS_13",
  "UPPS_14", "UPPS_15", "DEBQ_1", "DEBQ_2", "DEBQ_3", "DEBQ_4", "DEBQ_5",
  "DEBQ_6", "DEBQ_7", "DEBQ_8", "DEBQ_9", "DEBQ_10", "DEBQ_11", "DEBQ_12",
  "DEBQ_13", "CSS_1_Count", "CSS_2_Count", "CSS_3_Count", "CSS_4_Count",
  "CSS_5_Count", "CSS_6_Count", "CSS_7_Count", "CSS_8_Count", "CSS_9_Count",
  "CSS_10_Count", "CSS_11_Count", "CSS_12_Count", "CSS_13_Count", "CSS_14_Count",
  "CSS_15_Count", "CSS_16_Count", "CSS_17_Count", "CSS_18_Count", "UPPS_NU_avg",
  "UPPS_Persev_avg", "UPPS_Premed_avg", "UPPS_Sens_avg", "UPPS_PU_avg",
  "score_pinball", "score_robot", "hormone_assay_note",
  "source_raw_daily", "source_raw_daily_2", "source_supp_hormones", "source_final_batch"
)
# Helper functions for maximal filling via coalescing values across columns that share a base name
get_base_names <- function(nms) {
  gsub("\\..*$", "", nms)
}
maxfill_coalesce <- function(df, base) {
  cols <- names(df)[get_base_names(names(df)) == base]
  if (length(cols) == 0) {
    return(rep(NA, nrow(df)))
  } else if (length(cols) == 1) {
    return(df[[cols]])
  } else {
    return(coalesce(!!!df[cols]))
  }
}
# Apply maximal fill for each variable in the output list
for (v in final_vars) {
  merged_df[[v]] <- maxfill_coalesce(merged_df, v)
}

# --- 8. Select only the manually specified variables in the final output (including provenance flags) ---
# Subset merged data to just those columns, and filter out any rows missing 'id' or 'daterated'
final_df <- merged_df %>%
  select(all_of(final_vars)) %>%
  filter(!is.na(id) & !is.na(daterated))

# --- 9. Restore id/daterated types for analysis
# Convert 'id' to numeric, 'daterated' to Date, and set NA provenance flags to FALSE (logical)
final_df <- final_df %>%
  mutate(
    id = as.numeric(id),
    daterated = as.Date(daterated),
    source_raw_daily = ifelse(is.na(source_raw_daily), FALSE, source_raw_daily),
    source_raw_daily_2 = ifelse(is.na(source_raw_daily_2), FALSE, source_raw_daily_2),
    source_supp_hormones = ifelse(is.na(source_supp_hormones), FALSE, source_supp_hormones),
    source_final_batch = ifelse(is.na(source_final_batch), FALSE, source_final_batch)
  )

cat("Final maximally-filled merged dataset ready.\n")

# --- 10. Sort by id and daterated ---
# Arrange rows for analysis, convert id to factor, and create a 'date' column for downstream usage
final_df <- final_df %>%
  arrange(id, daterated) %>%
  mutate(id = as.factor(id)) %>% # Convert id to a factor for analysis 
  mutate(date=daterated) %>% # Create a 'date' column for menstrualcycleR functions
  # remove all observations where id == 210 and date is after 2020 or id==270 and date is after 2022-12-03
  filter(!(id == 270 & date > as.Date("2022-12-03"))) %>%
  filter(!(id == 279 & date > as.Date("2022-12-29"))) %>%
  filter(!(id == 210 & date > as.Date("2020-12-31")))

#View(final_df) # View final data interactively


# Inspect specific participants
final_df %>% filter(id == 279) %>% select(id, date, E2, P4, LH, BDEFS_1, score_pinball)
```


```{r}
# Rename final_df to df
df <- final_df
```


```{r}
# --- 11. Visualize missing hormone data ---
# Visualize missingness in key columns using visdat::vis_miss
miss_plot <- visdat::vis_miss(df %>% select(id, daterated, E2, BDEFS_1, score_pinball))
# Save plot to output folder with a dated descriptive name
ggsave(
  filename = file.path(output_folder, paste0("missingness_", Sys.Date(), ".png")),
  plot = miss_plot, width = 8, height = 5
)

# --- 12. Check which ids have the most missing hormone data ---
# Summarize missing values by id for hormones
missing_summary <- df %>%
  group_by(id) %>%
  summarise(
    total_days = n(),
    missing_E2 = sum(is.na(E2)),
    missing_P4 = sum(is.na(P4)),
    missing_LH = sum(is.na(LH))
  ) %>%
  arrange(desc(missing_E2), desc(missing_P4), desc(missing_LH))

#View(missing_summary) # View summary interactively

# Save summary table to a CSV file
write_csv(missing_summary, file.path(output_folder, paste0("missing_hormones_by_id_", Sys.Date(), ".csv")))

# --- Venn diagram for IDs with E2 and/or BDEFS data ---
# Make sets for Venn diagram
ids_e2 <- df %>%
  filter(!is.na(E2)) %>%
  distinct(id) %>%
  pull(id)

ids_bdefs <- df %>%
  filter(!is.na(BDEFS_1)) %>%
  distinct(id) %>%
  pull(id)

venn_data_e2_bdefs <- list(
  Has_E2 = ids_e2,
  Has_BDEFS = ids_bdefs
)

venn_plot <- ggvenn(venn_data_e2_bdefs, fill_color = c("#E69F00", "#56B4E9"))
# Save Venn diagram to output folder with a dated descriptive name
ggsave(
  filename = file.path(output_folder, paste0("e2_bdefs_venn_", Sys.Date(), ".png")),
  plot = venn_plot, width = 6, height = 4
)

# --- List IDs with NO E2 and NO BDEFS ---
# Find IDs lacking both key variables
ids_all <- unique(df$id)
ids_neither <- setdiff(ids_all, union(ids_e2, ids_bdefs))
print(ids_neither)
# Save to text file
write_lines(ids_neither, file.path(output_folder, paste0("ids_neither_e2_bdefs_", Sys.Date(), ".txt")))

# --- Table of which IDs have E2 and/or BDEFS ---
summary_df <- tibble(
  id = ids_all,
  has_e2 = id %in% ids_e2,
  has_bdefs = id %in% ids_bdefs
)
#View(summary_df)
# Save table to CSV
write_csv(summary_df, file.path(output_folder, paste0("ids_e2_bdefs_summary_", Sys.Date(), ".csv")))

```


# Check Merging and data availability across E2, P4, LH, and CSS_inatt
```{r}
# Check how many unique IDs are present in the final dataset
unique_ids <- unique(df$id)
cat("Number of unique IDs in the final dataset:", length(unique_ids), "\n")
```


# 5\. PROCESS & CALCULATE METRICS

```{r process-data}
# This chunk performs all the main data transformations, including merging the
# final cycle dates, scoring all questionnaires, and calculating derived metrics.

# --- 1. Merge Final Manually-Confirmed Cycle Dates ---
# This is the single source of truth for menses and ovulation events.
final_dates <- read_xls(path_final_dates) %>%
  select(id, date, menses = menses_final, ovtoday = ovtoday_final) %>%
  mutate(id = as.character(id), date = as.Date(date), menses = as.integer(menses), ovtoday = as.integer(ovtoday)) %>%
  filter(menses == 1 | ovtoday == 1)

df <- df %>%
  mutate(id = as.character(id)) %>% # Convert id to character for the join
  left_join(final_dates, by = c("id", "date")) %>%
  # After joining, non-event days are NA. coalesce() turns them into 0.
  mutate(
    menses = coalesce(menses, 0L),
    ovtoday = coalesce(ovtoday, 0L),
    id = as.factor(id) # Convert id to a factor for analysis
  )

# --- 2. Score Questionnaires (using original CamelCase names) ---
# This step calculates all summary scores from the raw item-level data.
df <- df %>%
  mutate(
    # Ensure all raw item columns are numeric before calculations.
    across(starts_with(c("CSS_B_", "DEBQ_", "BDEFS_")), ~as.numeric(as.character(.))),
    
    # Calculate mean scores for each scale.
    CSS_Inatt = rowMeans(across(c(CSS_B_1, CSS_B_3, CSS_B_5, CSS_B_7, CSS_B_9, CSS_B_11, CSS_B_13, CSS_B_15, CSS_B_17)), na.rm = TRUE),
    CSS_HypImp = rowMeans(across(c(CSS_B_2, CSS_B_4, CSS_B_6, CSS_B_8, CSS_B_10, CSS_B_12, CSS_B_14, CSS_B_16, CSS_B_18)), na.rm = TRUE),
    
    # Calculate symptom counts (number of items rated 2 or higher).
    CSS_Inatt_Count = rowSums(across(c(CSS_B_1, CSS_B_3, CSS_B_5, CSS_B_7, CSS_B_9, CSS_B_11, CSS_B_13, CSS_B_15, CSS_B_17), ~ .x >= 2), na.rm = TRUE),
    CSS_Hyp_Count   = rowSums(across(c(CSS_B_10, CSS_B_12, CSS_B_14, CSS_B_16, CSS_B_18), ~ .x >= 2), na.rm = TRUE),
    CSS_Imp_Count   = rowSums(across(c(CSS_B_2, CSS_B_4, CSS_B_6, CSS_B_8), ~ .x >= 2), na.rm = TRUE),
    CSS_HypImp_Count = CSS_Hyp_Count + CSS_Imp_Count,
    
    BDEFS_Total = rowMeans(across(starts_with("BDEFS_")), na.rm = TRUE),
    BDEFS_WM_avg = rowMeans(across(c(BDEFS_5)), na.rm = TRUE),
    BDEFS_RI_avg = rowMeans(across(c(BDEFS_6)), na.rm = TRUE),
    DEBQ_Total = rowMeans(across(starts_with("DEBQ_")), na.rm = TRUE),
    
    # Reverse code cognitive task scores where higher raw score = worse performance.
    score_pinball = as.numeric(score_pinball),
    score_robot = as.numeric(score_robot),
    score_pinball = max(score_pinball, na.rm = TRUE) - score_pinball,
    score_robot = max(score_robot, na.rm = TRUE) - score_robot
  )

# --- 3. Calculate All Derived Metrics (Rolling Averages & Standardized Scores) ---
# This single, efficient pipe creates all the .3roll, .5roll, .d, .zd, and .szd variables.
df <- df %>%
  group_by(id) %>% # All calculations until ungroup() are WITHIN-PERSON
  
  # Step 3a: Calculate rolling averages.
  mutate(across(.cols = all_of(alldailyvars), .fns = list(`3roll` = ~zoo::rollapply(., 3, mean, na.rm=T, align="center", fill=NA, partial=T), `5roll` = ~zoo::rollapply(., 5, mean, na.rm=T, align="center", fill=NA, partial=T)), .names = "{.col}.{.fn}")) %>%
  
  # Step 3b: Calculate person-standardized metrics (.d and .zd).
  mutate(across(.cols = c(all_of(alldailyvars), ends_with(".3roll"), ends_with(".5roll")), .fns = list(d = ~. - mean(., na.rm=T), zd = ~ (. - mean(., na.rm=T)) / sd(., na.rm=T)), .names = "{.col}.{.fn}")) %>%
  
  ungroup() %>% # Remove grouping to perform SAMPLE-WIDE calculations
  
  # Step 3c: Calculate sample-standardized metrics (.szd).
  mutate(across(.cols = c(all_of(alldailyvars), ends_with(".3roll"), ends_with(".5roll")), .fns = list(szd = ~ (. - mean(., na.rm=T)) / sd(., na.rm=T)), .names = "{.col}.{.fn}"))

# Sort df by id and date
df <- df %>%
  arrange(id, date)

cat("All processing and metric calculation complete.\n")


```

# 6\. DATA EXPLORATION & ANALYSIS

```{r analysis}
# --- 1. Visualize Data Availability ---
data_counts <- df %>%
  group_by(id) %>%
  summarize(
    days_in_study = n(),
    survey_days = sum(!is.na(DRSP_1)),
    hormone_days = sum(!is.na(E2))
  ) %>%
  pivot_longer(cols = -id, names_to = "data_type", values_to = "count")

availability_plot <- ggplot(data_counts, aes(x = data_type, y = count)) +
  geom_violin(aes(fill = data_type), alpha = 0.5, trim = FALSE) +
  geom_boxplot(width = 0.1, outlier.shape = NA) +
  geom_jitter(width = 0.1, alpha = 0.6) +
  facet_wrap(~ data_type, scales = "free_x") +
  labs(title = "Data Availability per Participant", y = "Number of Days", x = "") +
  theme_light() + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), legend.position = "none")
ggsave(filename = file.path(output_folder, "data_availability_distributions.png"), plot = availability_plot, width = 8, height = 6, dpi = 300)

# --- 2. Venn Diagram of Data Overlap ---
venn_list <- list(
  Survey_Data = data_counts %>% filter(data_type == "survey_days" & count > 0) %>% pull(id) %>% as.character(),
  Hormone_Data = data_counts %>% filter(data_type == "hormone_days" & count > 0) %>% pull(id) %>% as.character()
)
venn_plot <- ggvenn(venn_list, fill_color = c("#0073C2FF", "#EFC000FF"), stroke_size = 0.5, set_name_size = 4) +
  labs(title = "Overlap of Participants with Survey and Hormone Data")
ggsave(filename = file.path(output_folder, "data_overlap_venn_diagram.png"), plot = venn_plot, width = 6, height = 6, dpi = 300)

# --- 3. Run menstrualcycleR PACTS Scaling ---
df_for_pacts <- df %>% select(id, date, menses, ovtoday, any_of(alldailyvars))
df_scaled <- pacts_scaling(df_for_pacts, id=id, date=date, menses=menses, ovtoday=ovtoday, lower_cyclength_bound = 21, upper_cyclength_bound = 35)

# --- 4. Create PACTS Check Plots ---
# Set your variables to check
pacts_vars_to_check <- c("E2", "P4", "LH", "CSS_Inatt", "DEBQ_Total")

# Run the check function ONCE for all variables
results <- menstrualcycleR::cycledata_check(df_scaled, symptom_columns = pacts_vars_to_check)

# Print each plot to the active R device (e.g., RStudio Plots pane)
for (var in pacts_vars_to_check) {
  print(results$data_symptom_plots[[var]])
}

# Save each plot to PNG
pacts_plot_folder <- file.path(output_folder, "PACTS_Check_Plots")
if (!dir.exists(pacts_plot_folder)) dir.create(pacts_plot_folder, recursive = TRUE)

for (var in pacts_vars_to_check) {
  ggsave(
    filename = file.path(pacts_plot_folder, paste0("pacts_check_", var, ".png")),
    plot = results$data_symptom_plots[[var]],
    width = 8, height = 6, dpi = 300
  )
}

# --- 5. Create Sensitivity Dataset ---
omit_ids <- read_xlsx(path_omit_ids)
df_sens <- df_scaled %>%
  mutate(id = as.character(id)) %>%
  anti_join(mutate(omit_ids, id = as.character(id)), by = "id") %>%
  mutate(id = as.factor(id))

cat("Analysis and PACTS scaling complete.\n")

# View data for id 270
View(df_scaled %>% filter(id == 270))
```

# 7\. GENERATE HORMONE PLOTS

```{r generate-plots}
# --- Prepare Data for Plotting ---
hormones_long_all <- df %>%
  select(id, date, menses, ovtoday, matches("^(E2|P4|LH)(\\.|$)")) %>%
  pivot_longer(cols = -c(id, date, menses, ovtoday), names_to = "name", values_to = "value") %>%
  separate(name, into = c("hormone", "metric"), sep = "\\.", extra = "merge", fill = "right") %>%
  mutate(
    metric = replace_na(metric, "raw"),
    hormone = factor(hormone, levels = c("E2", "LH", "P4"))
    )

# --- Dynamic Plotting Loop ---
ids_list <- unique(df$id)
for (row in 1:nrow(metrics_to_plot)) {
  metric_name <- metrics_to_plot$metric_filter[row]; folder_name <- metrics_to_plot$folder_name[row]
  plot_subtitle <- metrics_to_plot$plot_subtitle[row]; should_facet <- metrics_to_plot$needs_facet[row]
  y_label <- metrics_to_plot$y_axis_label[row]
  current_output_dir <- file.path(output_folder, folder_name)
  if (!dir.exists(current_output_dir)) dir.create(current_output_dir, recursive = TRUE)
  cat("--- Generating plots for metric:", metric_name, "---\n")
  for (person_id in ids_list) {
    plot_data <- hormones_long_all %>% filter(id == person_id, metric == metric_name)
    if (nrow(plot_data) == 0 || all(is.na(plot_data$value))) next
    vline_data <- df %>% filter(id == person_id)
    p <- ggplot(plot_data, aes(x = date, y = value, color = hormone, group = hormone)) +
      geom_vline(data = filter(vline_data, menses == 1), aes(xintercept = date), color = "red", linewidth = 1) +
      geom_vline(data = filter(vline_data, ovtoday == 1), aes(xintercept = date), color = "purple", linewidth = 1) +
      geom_line(linewidth = 0.8) + geom_point(size = 1.5) +
      scale_x_date(breaks = "1 day", date_labels = "%b %d") +
      scale_color_manual(values = c("E2" = "#d95f02", "LH" = "#1b9e77", "P4" = "#7570b3")) +
      labs(title = paste("Participant:", person_id), subtitle = plot_subtitle, x = "Date", y = y_label, color = "Hormone") +
      theme_light() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
    if (should_facet) {
      p <- p + facet_wrap(~ hormone, ncol = 1, scales = "free_y", labeller = as_labeller(toupper)) + 
               theme(legend.position = "none")
      # ADD HORIZONTAL LINE AT Y=82 FOR RAW PROGESTERONE
      if (metric_name == "raw") {
        hline_data <- tibble(hormone = "P4", y = 82)
        p <- p + geom_hline(data = hline_data, aes(yintercept = y), linetype = "dashed", color = "#7570b3")
      }
    } else {
      p <- p + geom_hline(yintercept = 0, linetype = "dotted", color = "grey40")
    }
    plot_height <- if (should_facet) 8 else 7
    ggsave(filename = file.path(current_output_dir, paste0("plot_", person_id, ".png")), plot = p, width = 11, height = plot_height, dpi = 300)
  }
}
cat("--- All hormone plots generated successfully! ---\n")
```

# 8\. EXPORT FINAL DATASETS

```{r export-data}
# --- Define File Names ---
file_base_main <- paste0("adhd_daily_scaled_", format(Sys.Date(), "%Y%m%d"))
file_base_sens <- paste0("adhd_daily_SENS_scaled_", format(Sys.Date(), "%Y%m%d"))

# --- Save Main Scaled Dataset ---
write.csv(df_scaled, file.path(output_folder, paste0(file_base_main, ".csv")), row.names = FALSE)
save(df_scaled, file = file.path(output_folder, paste0(file_base_main, ".RData")))

# --- Save Sensitivity Dataset ---
write.csv(df_sens, file.path(output_folder, paste0(file_base_sens, ".csv")), row.names = FALSE)
save(df_sens, file = file.path(output_folder, paste0(file_base_sens, ".RData")))

cat("Final datasets exported successfully to:", output_folder, "\n")
```